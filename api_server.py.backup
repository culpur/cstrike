#!/usr/bin/env python3
"""
CStrike API Server
Provides REST API and WebSocket endpoints for the CStrike Web UI
"""

import os
import json
import logging
import psutil
import subprocess
from datetime import datetime, timezone
from pathlib import Path
from flask import Flask, jsonify, request, send_file
from flask_cors import CORS
from flask_socketio import SocketIO, emit
import threading
import time
import tempfile

# Import CStrike modules
from modules.recon import run_recon_layered
from modules.exploitation import run_exploitation_chain, run_bruteforce_enumeration
from modules.utils import get_target_dir
from modules.loot_tracker import (
    get_loot, add_loot, generate_credential_heatmap,
    get_credentials, get_all_credentials, get_credential_by_id,
    update_credential_validation
)
from modules.credential_validator import validate_credential, validate_credentials_batch
from modules.ai_assistant import ask_ai, get_thoughts

app = Flask(__name__)
CORS(app, origins=['http://localhost:3000'])
socketio = SocketIO(app, cors_allowed_origins=['http://localhost:3000'], async_mode='gevent')

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s %(levelname)s %(message)s'
)

# Load configuration
CONFIG_PATH = Path('.env')
CONFIG = json.loads(CONFIG_PATH.read_text()) if CONFIG_PATH.exists() else {}
TARGETS = CONFIG.get("target_scope", [])

# Global state
active_scans = {}
active_scans_lock = threading.Lock()  # Thread safety for concurrent scans
scan_threads = {}  # Track running threads for cancellation
system_metrics = {
    'cpu': 0,
    'memory': 0,  # Changed from 'ram' to match frontend
    'vpnIp': None,  # Changed from 'vpn_ip' to camelCase, None instead of string
    'uptime': 0,
    'timestamp': 0
}
services_status = {
    'metasploitRpc': 'stopped',  # Changed from 'metasploit' to match frontend
    'zap': 'stopped',
    'burp': 'stopped'
}
current_phase = 'idle'


def get_vpn_ip():
    """Get VPN IP address from wg0 or tun0"""
    import platform

    for iface in ['wg0', 'tun0', 'utun0', 'utun1', 'utun2']:  # Added macOS utun interfaces
        try:
            # Check if interface exists (platform-specific)
            if platform.system() == 'Darwin':  # macOS
                result = subprocess.run(
                    ['ifconfig', iface],
                    stdout=subprocess.PIPE,
                    stderr=subprocess.DEVNULL
                )
                if result.returncode == 0:
                    # Try to get external IP through this interface
                    try:
                        output = subprocess.check_output(
                            ['curl', '--interface', iface, '-s', '--connect-timeout', '2', 'https://ifconfig.me'],
                            stderr=subprocess.DEVNULL,
                            timeout=3
                        ).decode().strip()
                        if output:
                            return output
                    except:
                        pass
            else:  # Linux
                result = subprocess.run(
                    ['ip', 'link', 'show', iface],
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.DEVNULL
                )
                if result.returncode == 0:
                    output = subprocess.check_output(
                        ['curl', '--interface', iface, '-s', '--connect-timeout', '2', 'https://ifconfig.me'],
                        stderr=subprocess.DEVNULL,
                        timeout=3
                    ).decode().strip()
                    if output:
                        return output
        except Exception:
            continue
    return None  # Changed from 'Not connected' to None


def check_service_status(service_name):
    """Check if a service is running"""
    try:
        result = subprocess.run(['pgrep', '-f', service_name], stdout=subprocess.DEVNULL)
        return 'running' if result.returncode == 0 else 'stopped'
    except Exception:
        return 'unknown'


def update_system_metrics():
    """Background thread to update system metrics"""
    global system_metrics, services_status

    start_time = time.time()

    while True:
        try:
            # Update metrics
            system_metrics['cpu'] = psutil.cpu_percent(interval=1)
            system_metrics['memory'] = psutil.virtual_memory().percent
            system_metrics['vpnIp'] = get_vpn_ip()
            system_metrics['uptime'] = int(time.time() - start_time)
            system_metrics['timestamp'] = int(time.time() * 1000)  # Milliseconds

            # Update service status
            services_status['metasploitRpc'] = check_service_status('msfrpcd')
            services_status['zap'] = check_service_status('zap')
            services_status['burp'] = check_service_status('burpsuite')

            # Broadcast to WebSocket clients
            # Legacy event for backward compatibility
            socketio.emit('status_update', {
                'metrics': system_metrics,
                'services': services_status,
                'phase': current_phase
            })

            # New event for dashboard (matches frontend expectations)
            socketio.emit('system_metrics', system_metrics)

        except Exception as e:
            logging.error(f"Error updating metrics: {e}")

        time.sleep(2)  # Update every 2 seconds


# ==================== REST API ENDPOINTS ====================

@app.route('/api/v1/status', methods=['GET'])
def get_status():
    """Get current system status"""
    return jsonify({
        'metrics': system_metrics,
        'services': services_status,
        'phase': current_phase,
        'timestamp': datetime.now(timezone.utc).isoformat()
    })


@app.route('/api/v1/services', methods=['GET'])
def get_services():
    """Get service status"""
    return jsonify(services_status)


@app.route('/api/v1/services/<service_name>', methods=['POST'])
def control_service(service_name):
    """Start or stop a service"""
    action = request.json.get('action')  # 'start' or 'stop'

    service_commands = {
        'metasploitRpc': {
            'start': ['systemctl', 'start', 'msfrpcd'],
            'stop': ['pkill', '-f', 'msfrpcd']
        },
        'zap': {
            'start': ['zap', '-daemon'],
            'stop': ['pkill', '-f', 'zap']
        },
        'burp': {
            'start': ['burpsuite'],
            'stop': ['pkill', '-f', 'burpsuite']
        }
    }

    if service_name not in service_commands:
        return jsonify({'error': 'Unknown service'}), 404

    if action not in ['start', 'stop']:
        return jsonify({'error': 'Invalid action'}), 400

    try:
        subprocess.Popen(service_commands[service_name][action])
        time.sleep(1)  # Wait for service to start/stop
        services_status[service_name] = check_service_status(service_name)

        return jsonify({
            'service': service_name,
            'action': action,
            'status': services_status[service_name]
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/v1/services/<service_name>/restart', methods=['POST'])
def restart_service(service_name):
    """Restart a service"""
    # Map frontend names to process names
    process_map = {
        'metasploitRpc': 'msfrpcd',
        'zap': 'zap',
        'burp': 'burpsuite'
    }

    if service_name not in process_map:
        return jsonify({'error': 'Unknown service'}), 404

    try:
        process = process_map[service_name]
        # Stop
        subprocess.run(['pkill', '-f', process], check=False)
        time.sleep(2)

        # Start based on service
        if service_name == 'metasploitRpc':
            subprocess.Popen(['msfrpcd', '-P', 'password', '-S'])
        elif service_name == 'zap':
            subprocess.Popen(['zap.sh', '-daemon'])
        elif service_name == 'burp':
            subprocess.Popen(['burpsuite'])

        time.sleep(1)
        services_status[service_name] = check_service_status(process)

        return jsonify({
            'service': service_name,
            'action': 'restart',
            'status': services_status[service_name]
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/v1/targets', methods=['GET'])
def get_targets():
    """Get target list"""
    return jsonify({'targets': TARGETS})


@app.route('/api/v1/targets', methods=['POST'])
def add_target():
    """Add a new target"""
    target = request.json.get('target')
    if target and target not in TARGETS:
        TARGETS.append(target)
        # Update config file
        CONFIG['target_scope'] = TARGETS
        CONFIG_PATH.write_text(json.dumps(CONFIG, indent=2))
        return jsonify({'success': True, 'target': target})
    return jsonify({'error': 'Invalid or duplicate target'}), 400


@app.route('/api/v1/targets/<path:target_id>', methods=['DELETE'])
def remove_target(target_id):
    """Remove a target by URL or index"""
    # Try to parse as integer index first
    try:
        idx = int(target_id)
        if 0 <= idx < len(TARGETS):
            removed = TARGETS.pop(idx)
            CONFIG['target_scope'] = TARGETS
            CONFIG_PATH.write_text(json.dumps(CONFIG, indent=2))
            return jsonify({'success': True, 'removed': removed})
    except ValueError:
        # Not an integer, treat as URL string
        if target_id in TARGETS:
            TARGETS.remove(target_id)
            CONFIG['target_scope'] = TARGETS
            CONFIG_PATH.write_text(json.dumps(CONFIG, indent=2))
            return jsonify({'success': True, 'removed': target_id})

    return jsonify({'error': 'Target not found'}), 404


@app.route('/api/v1/config', methods=['GET'])
def get_config():
    """
    Read configuration from .env file

    Returns:
        {
          "openai_api_key": "sk-***",  # Masked
          "allow_exploitation": true,
          "scan_modes": ["port", "http", "dns", "vulnscan"],
          "allowed_tools": ["nmap", "ffuf", "sqlmap", ...],
          "max_threads": 10,
          "max_runtime": 300,
          "msf_username": "msf",
          "msf_password": "***",  # Masked
          "msf_host": "127.0.0.1",
          "msf_port": 55552,
          "zap_host": "127.0.0.1",
          "zap_port": 8090
        }
    """
    try:
        config = json.loads(CONFIG_PATH.read_text())

        # Mask sensitive fields
        if 'openai_api_key' in config and config['openai_api_key']:
            config['openai_api_key'] = config['openai_api_key'][:8] + '...'
        if 'msf_password' in config:
            config['msf_password'] = '***'

        return jsonify(config)
    except Exception as e:
        logging.error(f"Failed to read config: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/v1/config', methods=['PUT'])
def update_config():
    """
    Update configuration in .env file

    Request body: Complete config object (same as GET response)

    Note:
    - If API key is masked (ends with ...), preserve existing key
    - If password is ***, preserve existing password
    - Validate required fields
    """
    try:
        new_config = request.json

        if not new_config:
            return jsonify({'error': 'Request body required'}), 400

        # Load existing config
        existing_config = json.loads(CONFIG_PATH.read_text())

        # Preserve masked secrets
        if new_config.get('openai_api_key', '').endswith('...'):
            new_config['openai_api_key'] = existing_config.get('openai_api_key', '')
        if new_config.get('msf_password') == '***':
            new_config['msf_password'] = existing_config.get('msf_password', '')

        # Validate required fields
        required = ['allowed_tools', 'scan_modes', 'max_threads', 'max_runtime']
        for field in required:
            if field not in new_config:
                return jsonify({'error': f'Missing required field: {field}'}), 400

        # Validate field types
        if not isinstance(new_config.get('allowed_tools'), list):
            return jsonify({'error': 'allowed_tools must be an array'}), 400
        if not isinstance(new_config.get('scan_modes'), list):
            return jsonify({'error': 'scan_modes must be an array'}), 400
        if not isinstance(new_config.get('max_threads'), int):
            return jsonify({'error': 'max_threads must be an integer'}), 400
        if not isinstance(new_config.get('max_runtime'), int):
            return jsonify({'error': 'max_runtime must be an integer'}), 400

        # Write to .env
        CONFIG_PATH.write_text(json.dumps(new_config, indent=2))

        # Reload global config
        global CONFIG, TARGETS
        CONFIG = new_config
        TARGETS = CONFIG.get("target_scope", [])

        logging.info("Configuration updated successfully")

        return jsonify({'success': True, 'message': 'Configuration updated'})

    except Exception as e:
        logging.error(f"Failed to update config: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/v1/recon/start', methods=['POST'])
def start_recon():
    """Start reconnaissance scan - supports concurrent scanning"""
    target = request.json.get('target')
    tools = request.json.get('tools', [])

    if not target:
        return jsonify({'error': 'Target required'}), 400

    # Generate unique scan ID with timestamp and target hash
    scan_id = f"scan_{int(time.time() * 1000)}_{hash(target) % 10000}"

    # Create stop event for this scan
    stop_event = threading.Event()

    def run_scan():
        global current_phase
        try:
            # Update phase to recon
            current_phase = 'recon'
            socketio.emit('phase_change', {'phase': 'recon', 'target': target})

            # Emit scan start
            socketio.emit('recon_output', {
                'scan_id': scan_id,
                'target': target,
                'event': 'started',
                'message': f'Starting reconnaissance on {target}',
                'timestamp': datetime.now(timezone.utc).isoformat()
            })

            # Update scan status to running with tools info
            with active_scans_lock:
                active_scans[scan_id]['running_tools'] = tools
                active_scans[scan_id]['stop_event'] = stop_event

            # Check for cancellation before starting
            if stop_event.is_set():
                raise Exception("Scan cancelled before execution")

            results = run_recon_layered(target, socketio=socketio, scan_id=scan_id)

            # Check for cancellation after completion
            if stop_event.is_set():
                raise Exception("Scan cancelled")

            # Emit scan completion
            socketio.emit('recon_output', {
                'scan_id': scan_id,
                'target': target,
                'event': 'completed',
                'results': results,
                'timestamp': datetime.now(timezone.utc).isoformat()
            })

            with active_scans_lock:
                active_scans[scan_id].update({
                    'status': 'completed',
                    'results': results,
                    'completed_at': datetime.now(timezone.utc).isoformat()
                })
                # Clean up thread reference
                if scan_id in scan_threads:
                    del scan_threads[scan_id]

        except Exception as e:
            logging.error(f"Scan {scan_id} failed: {e}")
            socketio.emit('recon_output', {
                'scan_id': scan_id,
                'target': target,
                'event': 'failed',
                'error': str(e),
                'timestamp': datetime.now(timezone.utc).isoformat()
            })

            with active_scans_lock:
                active_scans[scan_id].update({
                    'status': 'failed' if 'cancelled' not in str(e).lower() else 'cancelled',
                    'error': str(e),
                    'completed_at': datetime.now(timezone.utc).isoformat()
                })
                # Clean up thread reference
                if scan_id in scan_threads:
                    del scan_threads[scan_id]

        finally:
            # Reset phase back to idle when scan completes
            current_phase = 'idle'
            socketio.emit('phase_change', {'phase': 'idle', 'target': target})

    # Store scan info BEFORE starting thread to avoid race condition
    with active_scans_lock:
        active_scans[scan_id] = {
            'status': 'running',
            'target': target,
            'tools': tools,
            'started_at': datetime.now(timezone.utc).isoformat(),
            'stop_event': stop_event
        }

    # Create and start thread after scan_id is registered
    thread = threading.Thread(target=run_scan, daemon=True)
    thread.start()

    # Store thread reference
    with active_scans_lock:
        scan_threads[scan_id] = thread

    return jsonify({'scan_id': scan_id, 'status': 'started', 'target': target})


@app.route('/api/v1/recon/status/<scan_id>', methods=['GET'])
def get_scan_status(scan_id):
    """Get scan status"""
    with active_scans_lock:
        if scan_id in active_scans:
            # Return copy without stop_event (not JSON serializable)
            scan_info = {k: v for k, v in active_scans[scan_id].items() if k != 'stop_event'}
            return jsonify(scan_info)
    return jsonify({'error': 'Scan not found'}), 404


@app.route('/api/v1/recon/active', methods=['GET'])
def get_active_scans():
    """Get all currently active (running) scans"""
    with active_scans_lock:
        active = []
        for scan_id, scan_info in active_scans.items():
            if scan_info.get('status') == 'running':
                # Create clean copy without stop_event
                clean_info = {
                    'scan_id': scan_id,
                    'target': scan_info.get('target'),
                    'tools': scan_info.get('tools', []),
                    'running_tools': scan_info.get('running_tools', []),
                    'started_at': scan_info.get('started_at'),
                    'status': scan_info.get('status')
                }
                active.append(clean_info)

    return jsonify({
        'active_scans': active,
        'count': len(active)
    })


@app.route('/api/v1/recon/batch', methods=['POST'])
def start_batch_recon():
    """Start reconnaissance scans on multiple targets simultaneously"""
    targets = request.json.get('targets', [])
    tools = request.json.get('tools', [])

    if not targets or not isinstance(targets, list):
        return jsonify({'error': 'targets array required'}), 400

    if len(targets) == 0:
        return jsonify({'error': 'At least one target required'}), 400

    # Limit concurrent scans for safety
    MAX_CONCURRENT_SCANS = 10
    if len(targets) > MAX_CONCURRENT_SCANS:
        return jsonify({
            'error': f'Maximum {MAX_CONCURRENT_SCANS} concurrent scans allowed'
        }), 400

    scan_ids = []
    failed_targets = []

    for target in targets:
        if not target or not isinstance(target, str):
            failed_targets.append({'target': target, 'reason': 'Invalid target format'})
            continue

        try:
            # Generate unique scan ID
            scan_id = f"scan_{int(time.time() * 1000)}_{hash(target) % 10000}"
            stop_event = threading.Event()

            def run_scan(target_url=target, sid=scan_id, stop_evt=stop_event):
                try:
                    # Emit scan start
                    socketio.emit('recon_output', {
                        'scan_id': sid,
                        'target': target_url,
                        'event': 'started',
                        'message': f'Starting batch reconnaissance on {target_url}',
                        'timestamp': datetime.now(timezone.utc).isoformat()
                    })

                    # Update scan status
                    with active_scans_lock:
                        active_scans[sid]['running_tools'] = tools

                    if stop_evt.is_set():
                        raise Exception("Scan cancelled before execution")

                    results = run_recon_layered(target_url, socketio=socketio, scan_id=sid)

                    if stop_evt.is_set():
                        raise Exception("Scan cancelled")

                    # Emit completion
                    socketio.emit('recon_output', {
                        'scan_id': sid,
                        'target': target_url,
                        'event': 'completed',
                        'results': results,
                        'timestamp': datetime.now(timezone.utc).isoformat()
                    })

                    with active_scans_lock:
                        active_scans[sid].update({
                            'status': 'completed',
                            'results': results,
                            'completed_at': datetime.now(timezone.utc).isoformat()
                        })
                        if sid in scan_threads:
                            del scan_threads[sid]

                except Exception as e:
                    logging.error(f"Batch scan {sid} failed: {e}")
                    socketio.emit('recon_output', {
                        'scan_id': sid,
                        'target': target_url,
                        'event': 'failed',
                        'error': str(e),
                        'timestamp': datetime.now(timezone.utc).isoformat()
                    })

                    with active_scans_lock:
                        active_scans[sid].update({
                            'status': 'failed' if 'cancelled' not in str(e).lower() else 'cancelled',
                            'error': str(e),
                            'completed_at': datetime.now(timezone.utc).isoformat()
                        })
                        if sid in scan_threads:
                            del scan_threads[sid]

            # Create and start thread
            thread = threading.Thread(target=run_scan, daemon=True)
            thread.start()

            # Store scan info
            with active_scans_lock:
                active_scans[scan_id] = {
                    'status': 'running',
                    'target': target,
                    'tools': tools,
                    'started_at': datetime.now(timezone.utc).isoformat(),
                    'stop_event': stop_event,
                    'batch': True
                }
                scan_threads[scan_id] = thread

            scan_ids.append(scan_id)

        except Exception as e:
            logging.error(f"Failed to start scan for {target}: {e}")
            failed_targets.append({'target': target, 'reason': str(e)})

    response = {
        'status': 'started',
        'scan_ids': scan_ids,
        'successful': len(scan_ids),
        'total': len(targets)
    }

    if failed_targets:
        response['failed'] = failed_targets

    return jsonify(response), 200 if len(scan_ids) > 0 else 400


@app.route('/api/v1/recon/scans/<scan_id>', methods=['DELETE'])
def cancel_scan(scan_id):
    """Cancel a running scan and clean up resources"""
    with active_scans_lock:
        if scan_id not in active_scans:
            return jsonify({'error': 'Scan not found'}), 404

        scan_info = active_scans[scan_id]

        if scan_info.get('status') != 'running':
            return jsonify({
                'error': f'Scan is not running (status: {scan_info.get("status")})'
            }), 400

        # Set stop event to signal cancellation
        stop_event = scan_info.get('stop_event')
        if stop_event:
            stop_event.set()

        # Update status
        scan_info['status'] = 'cancelling'
        scan_info['cancel_requested_at'] = datetime.now(timezone.utc).isoformat()

    # Emit cancellation event
    socketio.emit('recon_output', {
        'scan_id': scan_id,
        'target': scan_info.get('target'),
        'event': 'cancelled',
        'message': 'Scan cancellation requested',
        'timestamp': datetime.now(timezone.utc).isoformat()
    })

    return jsonify({
        'scan_id': scan_id,
        'status': 'cancelling',
        'message': 'Scan cancellation requested. The scan will stop shortly.'
    })


@app.route('/api/v1/loot/<path:target>', methods=['GET'])
def get_target_loot(target):
    """Get loot for a target (URL-encoded or path format)"""
    # Flask automatically decodes URL-encoded parameters
    category = request.args.get('category')

    if category:
        loot = get_loot(target, category)
    else:
        # Get all loot categories
        loot = {
            'usernames': get_loot(target, 'username'),
            'passwords': get_loot(target, 'password'),
            'urls': get_loot(target, 'url'),
            'ports': get_loot(target, 'port')
        }

    return jsonify(loot)


@app.route('/api/v1/loot/heatmap', methods=['GET'])
def get_loot_heatmap():
    """
    Get credential heatmap with priority scoring.

    Query parameters:
        limit (int): Maximum number of credentials to return (default: 50)
        min_score (float): Minimum score threshold (default: 0)

    Returns:
        JSON array of scored credentials sorted by priority (highest first)
    """
    try:
        limit = request.args.get('limit', 50, type=int)
        min_score = request.args.get('min_score', 0, type=float)

        # Limit bounds checking
        limit = max(1, min(limit, 500))  # Between 1 and 500

        # Generate heatmap
        heatmap = generate_credential_heatmap(limit=limit)

        # Filter by minimum score if specified
        if min_score > 0:
            heatmap = [cred for cred in heatmap if cred['score'] >= min_score]

        return jsonify({
            'credentials': heatmap,
            'count': len(heatmap),
            'timestamp': datetime.now(timezone.utc).isoformat()
        })

    except Exception as e:
        logging.error(f"Heatmap generation failed: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/v1/loot/credentials', methods=['GET'])
def get_all_creds():
    """Get all credentials across all targets"""
    try:
        target = request.args.get('target')

        if target:
            credentials = get_credentials(target)
        else:
            credentials = get_all_credentials()

        return jsonify({
            'credentials': credentials,
            'count': len(credentials),
            'timestamp': datetime.now(timezone.utc).isoformat()
        })

    except Exception as e:
        logging.error(f"Failed to retrieve credentials: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/v1/loot/credentials/validate', methods=['POST'])
def validate_single_credential():
    """
    Validate a single credential against target service

    Request body:
        {
            "credential_id": "cred_123",
            "target": "192.168.1.10",
            "username": "admin",
            "password": "password123",
            "service": "ssh",
            "port": 22  // optional
        }

    Returns:
        {
            "credential_id": "cred_123",
            "valid": true/false,
            "service": "ssh",
            "target": "192.168.1.10",
            "username": "admin",
            "tested_at": "2025-12-25T10:00:00Z",
            "error": null,
            "details": {...}
        }
    """
    try:
        data = request.json

        # Validate required fields
        required_fields = ['credential_id', 'target', 'username', 'password', 'service']
        missing_fields = [field for field in required_fields if field not in data]

        if missing_fields:
            return jsonify({
                'error': f'Missing required fields: {", ".join(missing_fields)}'
            }), 400

        # Extract credential data
        credential_id = data['credential_id']
        target = data['target']
        username = data['username']
        password = data['password']
        service = data['service']
        port = data.get('port')

        # Perform validation in background thread to avoid blocking
        def run_validation():
            try:
                result = validate_credential(
                    credential_id=credential_id,
                    target=target,
                    username=username,
                    password=password,
                    service=service,
                    port=port
                )

                # Update loot tracker with result
                update_credential_validation(credential_id, result)

                # Emit WebSocket event for real-time updates
                socketio.emit('loot_item', {
                    'event': 'credential_validated',
                    'credential_id': credential_id,
                    'result': result,
                    'timestamp': datetime.now(timezone.utc).isoformat()
                })

                logging.info(
                    f"Credential {credential_id} validated: "
                    f"{result['valid']} ({service}://{username}@{target})"
                )

            except Exception as e:
                logging.error(f"Validation thread error for {credential_id}: {e}")

        # Start validation in background
        thread = threading.Thread(target=run_validation, daemon=True)
        thread.start()

        return jsonify({
            'status': 'started',
            'message': 'Credential validation initiated',
            'credential_id': credential_id
        })

    except Exception as e:
        logging.error(f"Credential validation request failed: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/v1/loot/credentials/validate/batch', methods=['POST'])
def validate_batch_credentials():
    """
    Validate multiple credentials in batch

    Request body:
        {
            "credentials": [
                {
                    "credential_id": "cred_1",
                    "target": "192.168.1.10",
                    "username": "admin",
                    "password": "password123",
                    "service": "ssh",
                    "port": 22  // optional
                },
                ...
            ]
        }

    Returns:
        {
            "status": "started",
            "count": 5,
            "message": "Batch validation initiated for 5 credentials"
        }
    """
    try:
        data = request.json
        credentials = data.get('credentials', [])

        if not credentials or not isinstance(credentials, list):
            return jsonify({'error': 'credentials array required'}), 400

        if len(credentials) == 0:
            return jsonify({'error': 'At least one credential required'}), 400

        # Limit batch size for safety
        MAX_BATCH_SIZE = 50
        if len(credentials) > MAX_BATCH_SIZE:
            return jsonify({
                'error': f'Maximum {MAX_BATCH_SIZE} credentials allowed per batch'
            }), 400

        # Validate all credentials have required fields
        for i, cred in enumerate(credentials):
            required_fields = ['credential_id', 'target', 'username', 'password', 'service']
            missing = [f for f in required_fields if f not in cred]

            if missing:
                return jsonify({
                    'error': f'Credential at index {i} missing fields: {", ".join(missing)}'
                }), 400

        # Process batch validation in background
        def run_batch_validation():
            try:
                results = validate_credentials_batch(credentials)

                # Update loot tracker and emit events for each result
                for result in results:
                    credential_id = result['credential_id']

                    # Update storage
                    update_credential_validation(credential_id, result)

                    # Emit WebSocket event
                    socketio.emit('loot_item', {
                        'event': 'credential_validated',
                        'credential_id': credential_id,
                        'result': result,
                        'timestamp': datetime.now(timezone.utc).isoformat()
                    })

                # Emit batch completion event
                valid_count = sum(1 for r in results if r['valid'])
                socketio.emit('loot_item', {
                    'event': 'batch_validation_complete',
                    'total': len(results),
                    'valid': valid_count,
                    'invalid': len(results) - valid_count,
                    'timestamp': datetime.now(timezone.utc).isoformat()
                })

                logging.info(
                    f"Batch validation complete: {valid_count}/{len(results)} valid"
                )

            except Exception as e:
                logging.error(f"Batch validation thread error: {e}")

        # Start batch validation in background
        thread = threading.Thread(target=run_batch_validation, daemon=True)
        thread.start()

        return jsonify({
            'status': 'started',
            'count': len(credentials),
            'message': f'Batch validation initiated for {len(credentials)} credentials'
        })

    except Exception as e:
        logging.error(f"Batch validation request failed: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/v1/ai/thoughts', methods=['GET'])
def get_ai_thoughts():
    """Get recent AI thoughts"""
    thoughts = get_thoughts()
    return jsonify({'thoughts': thoughts})


@app.route('/api/v1/ai/analyze', methods=['POST'])
def analyze_with_ai():
    """Trigger AI analysis on target data"""
    target = request.json.get('target')
    phase = request.json.get('phase', 'recon')  # recon or exploitation

    if not target:
        return jsonify({'error': 'Target required'}), 400

    def run_ai_analysis():
        global current_phase
        current_phase = f'ai_{phase}'
        socketio.emit('phase_change', {'phase': current_phase, 'target': target})

        try:
            # Load recon results for the target
            from pathlib import Path
            results_file = Path(f'results/{target}/results.json')

            if results_file.exists():
                with open(results_file, 'r') as f:
                    recon_data = json.load(f)
            else:
                recon_data = {'message': f'No recon data found for {target}'}

            # Ask AI for analysis (now emits detailed WebSocket events)
            ai_response = ask_ai(recon_data, socketio=socketio, target=target)

            if ai_response:
                # Parse commands from AI response (also emits events)
                from modules.ai_assistant import parse_ai_commands
                commands = parse_ai_commands(ai_response, socketio=socketio, target=target)

                # Emit execution plan
                if commands:
                    socketio.emit('ai_thought', {
                        'target': target,
                        'thoughtType': 'ai_execution',
                        'content': f'Ready to execute {len(commands)} commands',
                        'metadata': {
                            'commands': [' '.join(cmd) for cmd in commands],
                            'note': 'Commands will be executed when exploitation phase is triggered'
                        },
                        'timestamp': datetime.now(timezone.utc).isoformat()
                    })
                else:
                    socketio.emit('ai_thought', {
                        'target': target,
                        'thoughtType': 'observation',
                        'content': 'No executable commands found in AI response',
                        'timestamp': datetime.now(timezone.utc).isoformat()
                    })

            return {'success': True, 'response': ai_response}

        except Exception as e:
            logging.error(f"AI analysis failed: {e}")
            socketio.emit('ai_thought', {
                'target': target,
                'thoughtType': 'observation',
                'content': f'âŒ Analysis failed: {str(e)}',
                'timestamp': datetime.now(timezone.utc).isoformat()
            })
            return {'error': str(e)}

        finally:
            current_phase = 'idle'
            socketio.emit('phase_change', {'phase': 'idle', 'target': target})

    # Run in background thread
    thread = threading.Thread(target=run_ai_analysis, daemon=True)
    thread.start()

    return jsonify({'status': 'started', 'message': 'AI analysis initiated'})


@app.route('/api/v1/exploit/start', methods=['POST'])
def start_exploitation():
    """Start exploitation chain with configurable tools"""
    target = request.json.get('target')
    tools = request.json.get('tools', ['nuclei', 'ffuf'])  # NEW: Tool selection

    if not target:
        return jsonify({'error': 'Target required'}), 400

    exploit_id = f"exploit_{int(time.time())}"

    def run_exploitation():
        global current_phase
        current_phase = 'exploitation'
        socketio.emit('phase_change', {'phase': 'exploitation', 'target': target})

        try:
            socketio.emit('exploit_result', {
                'exploit_id': exploit_id,
                'target': target,
                'event': 'started',
                'message': f'Starting exploitation on {target}',
                'tools': tools,
                'timestamp': datetime.now(timezone.utc).isoformat()
            })

            # Pass tools to exploitation chain
            target_dir = get_target_dir(target)
            run_exploitation_chain(target, target_dir, enabled_tools=tools)

            socketio.emit('exploit_result', {
                'exploit_id': exploit_id,
                'target': target,
                'event': 'completed',
                'message': 'Exploitation chain completed',
                'timestamp': datetime.now(timezone.utc).isoformat()
            })

        except Exception as e:
            logging.error(f"Exploitation {exploit_id} failed: {e}")
            socketio.emit('exploit_result', {
                'exploit_id': exploit_id,
                'target': target,
                'event': 'failed',
                'error': str(e),
                'timestamp': datetime.now(timezone.utc).isoformat()
            })

        finally:
            current_phase = 'idle'
            socketio.emit('phase_change', {'phase': 'idle', 'target': target})

    thread = threading.Thread(target=run_exploitation, daemon=True)
    thread.start()

    return jsonify({
        'exploit_id': exploit_id,
        'status': 'started',
        'target': target,
        'tools': tools
    })


@app.route('/api/v1/exploit/bruteforce', methods=['POST'])
def start_bruteforce():
    """Start targeted bruteforce attack"""
    target = request.json.get('target')
    service = request.json.get('service', 'ssh').lower()
    port = request.json.get('port', 22)
    wordlist = request.json.get('wordlist', 'rockyou.txt')

    if not target:
        return jsonify({'error': 'Target required'}), 400

    exploit_id = f"bruteforce_{int(time.time())}"

    def run_bruteforce():
        global current_phase
        current_phase = 'exploitation'
        socketio.emit('phase_change', {'phase': 'exploitation', 'target': target})

        try:
            socketio.emit('exploit_result', {
                'exploit_id': exploit_id,
                'target': target,
                'service': service,
                'port': port,
                'event': 'started',
                'message': f'Starting bruteforce attack on {service}://{target}:{port}',
                'timestamp': datetime.now(timezone.utc).isoformat()
            })

            # Run Hydra bruteforce
            run_bruteforce_enumeration(target, [str(port)])

            socketio.emit('exploit_result', {
                'exploit_id': exploit_id,
                'target': target,
                'event': 'completed',
                'message': f'Bruteforce attack completed on {service}',
                'timestamp': datetime.now(timezone.utc).isoformat()
            })

        except Exception as e:
            logging.error(f"Bruteforce {exploit_id} failed: {e}")
            socketio.emit('exploit_result', {
                'exploit_id': exploit_id,
                'target': target,
                'event': 'failed',
                'error': str(e),
                'timestamp': datetime.now(timezone.utc).isoformat()
            })

        finally:
            current_phase = 'idle'
            socketio.emit('phase_change', {'phase': 'idle', 'target': target})

    thread = threading.Thread(target=run_bruteforce, daemon=True)
    thread.start()

    return jsonify({
        'status': 'started',
        'exploit_id': exploit_id,
        'target': target,
        'service': service,
        'port': port
    })


@app.route('/api/v1/logs', methods=['GET'])
def get_logs():
    """Get recent logs with proper structured format"""
    limit = request.args.get('limit', 1000, type=int)
    level = request.args.get('level')  # DEBUG, INFO, WARN, ERROR

    log_file = Path('logs/driver.log')
    if not log_file.exists():
        return jsonify({'logs': []})

    with open(log_file, 'r') as f:
        lines = f.readlines()[-limit:]

    # Filter by level if specified
    if level:
        lines = [line for line in lines if level in line]

    logs = []
    for idx, line in enumerate(lines):
        try:
            parts = line.split(maxsplit=3)
            if len(parts) >= 4:
                # Parse timestamp, level, message
                timestamp_str = f"{parts[0]} {parts[1]}"
                log_level = parts[2]
                message = parts[3].strip()

                # Try to parse timestamp to ISO format
                try:
                    dt = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S,%f')
                    iso_timestamp = dt.replace(tzinfo=timezone.utc).isoformat()
                except:
                    iso_timestamp = datetime.now(timezone.utc).isoformat()

                logs.append({
                    'id': f"{int(time.time() * 1000)}-{idx:04d}-{os.urandom(2).hex()}",
                    'timestamp': iso_timestamp,
                    'level': log_level,
                    'source': 'system',
                    'message': message,
                    'metadata': {}
                })
            else:
                # Unstructured log line
                logs.append({
                    'id': f"{int(time.time() * 1000)}-{idx:04d}-{os.urandom(2).hex()}",
                    'timestamp': datetime.now(timezone.utc).isoformat(),
                    'level': 'INFO',
                    'source': 'system',
                    'message': line.strip(),
                    'metadata': {}
                })
        except Exception as e:
            # Fallback for parsing errors
            logs.append({
                'id': f"{int(time.time() * 1000)}-{idx:04d}-{os.urandom(2).hex()}",
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'level': 'INFO',
                'source': 'system',
                'message': line.strip(),
                'metadata': {'parse_error': str(e)}
            })

    return jsonify({'logs': logs})


# ==================== WEBSOCKET HANDLERS ====================

@socketio.on('connect')
def handle_connect():
    """Handle WebSocket connection"""
    logging.info(f"Client connected: {request.sid}")
    emit('connected', {'message': 'Connected to CStrike API'})


@socketio.on('disconnect')
def handle_disconnect():
    """Handle WebSocket disconnection"""
    logging.info(f"Client disconnected: {request.sid}")


@socketio.on('subscribe')
def handle_subscribe(data):
    """Subscribe to event types"""
    event_types = data.get('events', [])
    logging.info(f"Client {request.sid} subscribed to: {event_types}")
    emit('subscribed', {'events': event_types})


@socketio.on('ping')
def handle_ping():
    """Handle ping for keepalive"""
    emit('pong', {'timestamp': datetime.now(timezone.utc).isoformat()})


# ==================== MAIN ====================

if __name__ == '__main__':
    # Start metrics update thread
    metrics_thread = threading.Thread(target=update_system_metrics, daemon=True)
    metrics_thread.start()

    logging.info("ðŸš€ CStrike API Server starting...")
    logging.info("ðŸ“¡ REST API: http://localhost:8000/api/v1/")
    logging.info("ðŸ”Œ WebSocket: ws://localhost:8000/")
    logging.info("ðŸŽ¯ Frontend: http://localhost:3000")

    # Disable reloader to prevent port binding issues
    socketio.run(app, host='0.0.0.0', port=8000, debug=True, use_reloader=False, allow_unsafe_werkzeug=True)
